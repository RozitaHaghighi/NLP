{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPOdKm1Oso4e",
        "outputId": "5fffc186-7c9b-4943-9dc1-f7d14ebe6f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading embeddings...\n",
            "Extracting embeddings...\n",
            "Embeddings extracted to: ./data/wiki-news-300d-1M.vec\n",
            "Download and extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL for the FastText embeddings\n",
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
        "zip_path = \"wiki-news-300d-1M.vec.zip\"\n",
        "extract_dir = \"./data\"\n",
        "\n",
        "# Download the zip file\n",
        "print(\"Downloading embeddings...\")\n",
        "urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "# Extract the contents\n",
        "print(\"Extracting embeddings...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Verify the extracted file\n",
        "embedding_path = os.path.join(extract_dir, \"wiki-news-300d-1M.vec\")\n",
        "print(f\"Embeddings extracted to: {embedding_path}\")\n",
        "print(\"Download and extraction complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Path to the extracted FastText embeddings\n",
        "fasttext_path = './data/wiki-news-300d-1M.vec'\n",
        "\n",
        "# Load the embeddings\n",
        "print(\"Loading FastText embeddings...\")\n",
        "model = KeyedVectors.load_word2vec_format(fasttext_path, binary=False)\n",
        "print(\"Embeddings loaded successfully!\")\n",
        "\n",
        "# Test: Find the vector for 'apple'\n",
        "print(\"\\nVector for 'apple':\")\n",
        "print(model['apple'])\n",
        "\n",
        "# Test: Find the most similar words to 'apple'\n",
        "print(\"\\nMost similar words to 'apple':\")\n",
        "similar_words = model.most_similar('apple', topn=5)\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT5MwfXEvIPW",
        "outputId": "98795f8b-63ae-4ada-afd1-a256f39755f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FastText embeddings...\n",
            "Embeddings loaded successfully!\n",
            "\n",
            "Vector for 'apple':\n",
            "[-0.066  -0.027  -0.0403  0.0651 -0.0168 -0.0405  0.1743  0.0953 -0.0455\n",
            "  0.0235 -0.2745 -0.0228 -0.1808  0.0835 -0.0733  0.127  -0.076   0.0418\n",
            " -0.0321 -0.1173 -0.2255  0.1108 -0.0487 -0.0328 -0.1202 -0.0645 -0.0133\n",
            "  0.1224 -0.1095  0.1556  0.355   0.2831  0.0757  0.0459  0.0502  0.0282\n",
            "  0.036   0.1501 -0.1976 -0.0697 -0.0221  0.0708 -0.0812 -0.0199  0.0299\n",
            "  0.2296  0.1669  0.1569 -0.1004  0.0126 -0.0841 -0.2551 -0.7234 -0.1224\n",
            " -0.1237  0.1448  0.0594 -0.0535  0.0048  0.0465  0.1258 -0.1345 -0.1895\n",
            " -0.1805  0.0839 -0.2655  0.2866 -0.0662 -0.1446 -0.0867 -0.1296  0.1133\n",
            " -0.1888  0.0754 -0.0438  0.0416  0.2305  0.0672  0.1048 -0.0222  0.0622\n",
            "  0.1131 -0.0529 -0.1493  0.2413  0.2086 -0.0391  0.1578  0.2828 -0.1328\n",
            "  0.0055  0.0099  0.209  -0.1234  0.201   0.0484 -0.0601 -0.0774  0.115\n",
            " -0.2089 -0.1844  0.1884 -0.0387  0.0153  0.0716 -0.1435  0.0174  0.1532\n",
            "  0.0087  0.1044 -0.0441  0.1227  0.1691  0.0465 -0.1376  0.1054 -0.0148\n",
            " -0.0937 -0.1588 -0.243  -0.1988  0.2598  0.0051 -0.0623 -0.1671  0.191\n",
            " -0.0608 -0.1661 -0.0086  0.0143 -0.1009  0.043   0.1265  0.0278 -0.0542\n",
            "  0.0059  0.0631  0.0435 -0.0949  0.0282  0.039   0.1548 -0.3156  0.215\n",
            "  0.0743  0.0294 -0.0849  0.0729 -0.0994  0.0075 -0.2072  0.2067  0.2009\n",
            "  0.0122  0.2906  0.1983  0.1061  0.0493 -0.0771 -0.1069 -0.1237  0.0436\n",
            "  0.2055 -0.0064 -0.0097  0.0528  0.087   0.2557  0.0344  0.0444  0.0193\n",
            "  0.2192 -0.0299 -0.0732  0.0868 -0.0704  0.3651 -0.0628 -0.0638  0.0403\n",
            " -0.0116  0.1585 -0.1026 -0.0101 -0.0021 -0.0925 -0.0543 -0.0314 -0.1664\n",
            " -0.2343 -0.064   0.0226  0.2008 -0.108  -0.0187  0.2017  0.0266 -0.016\n",
            "  0.0525  0.1695  0.0994 -0.0586  0.011   0.0113  0.0391  0.0326 -0.0401\n",
            " -0.1596  0.0138 -0.0775  0.0254  0.049  -0.1648 -0.163   0.1313  0.0031\n",
            "  0.0281 -0.0096 -0.1172 -0.0028 -0.0427 -0.0135 -0.1001 -0.0806  0.094\n",
            " -0.2337  0.0433  0.0836  0.0046 -0.0698  0.0524  0.1357  0.3148 -0.1133\n",
            " -0.0267 -0.1433 -0.1679 -0.1372 -0.2248 -0.0545 -0.0134  0.012   0.0579\n",
            "  0.0661  0.2275 -0.1757 -0.0465 -0.0016  0.1491  0.4331  0.0528  0.0576\n",
            "  0.0788 -0.1633 -0.0057  0.0796 -0.1792 -0.1099 -0.1514  0.0956  0.0896\n",
            " -0.0359 -0.0586  0.0048 -0.376   0.0015 -0.0131 -0.2128 -0.149  -0.0134\n",
            " -0.0551  0.0905 -0.2922  0.0762  0.1334  0.0306 -0.0771  0.0621  0.1225\n",
            "  0.039  -0.0624 -0.1299 -0.0208  0.3638 -0.1391 -0.1281  0.0686 -0.1273\n",
            " -0.2477  0.0916 -0.1019  0.0689  0.2031  0.0965 -0.0312  0.0316 -0.0671\n",
            "  0.0381  0.0631 -0.1562]\n",
            "\n",
            "Most similar words to 'apple':\n",
            "apples: 0.8038\n",
            "pear: 0.7096\n",
            "orchard: 0.6769\n",
            "fruit: 0.6674\n",
            "pippin: 0.6674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "# Load the FastText embeddings\n",
        "print(\"Loading FastText embeddings...\")\n",
        "fasttext_path = './data/wiki-news-300d-1M.vec'\n",
        "model = KeyedVectors.load_word2vec_format(fasttext_path, binary=False)\n",
        "print(\"Embeddings loaded successfully!\")\n",
        "\n",
        "# Create a word-to-index mapping from the embeddings\n",
        "word_to_index = {word: idx for idx, word in enumerate(model.index_to_key)}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbuEhM1evnxw",
        "outputId": "2c8d6c9c-dbb9-48e9-9c51-b30143112e85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FastText embeddings...\n",
            "Embeddings loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(word, model, word_to_index):\n",
        "    \"\"\"Retrieve the embedding for a given word.\"\"\"\n",
        "    return model[word]\n",
        "\n",
        "def get_k_nearest_words(k, result_embedding, model, word_to_index):\n",
        "    \"\"\"Find the k nearest words to the given embedding.\"\"\"\n",
        "    most_similar = model.similar_by_vector(result_embedding, topn=k)\n",
        "    return [word for word, _ in most_similar]\n",
        "\n",
        "def test_analogy(model, word_to_index, analogy_file, subset_size=None):\n",
        "    \"\"\"\n",
        "    Method to test accuracy of embeddings on analogy tasks.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    model : KeyedVectors\n",
        "        Trained word embeddings model.\n",
        "    word_to_index : Dictionary\n",
        "        Dictionary mapping words to indices {word: index}.\n",
        "    analogy_file : String\n",
        "        File containing analogy tasks.\n",
        "    subset_size : int, optional\n",
        "        Number of rows to use from the dataset (for testing purposes).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    accuracy : float\n",
        "        Accuracy of the model on the analogy tasks.\n",
        "    \"\"\"\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(analogy_file)\n",
        "\n",
        "    # Filter by the 'capital-common-countries' category\n",
        "    df = df[df['category'] == 'capital-common-countries']\n",
        "\n",
        "    # Reduce the dataset size for testing, if subset_size is provided\n",
        "    if subset_size:\n",
        "        df = df.head(subset_size)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    skipped = 0  # Counter for skipped tasks\n",
        "\n",
        "    # Iterate through each analogy task\n",
        "    for index, row in df.iterrows():\n",
        "        word_one = row['word_one'].lower()\n",
        "        word_two = row['word_two'].lower()\n",
        "        word_three = row['word_three'].lower()\n",
        "        word_four = row['word_four'].lower()\n",
        "\n",
        "        # Skip tasks if any word is not in the vocabulary\n",
        "        if (word_one not in word_to_index) or (word_two not in word_to_index) or \\\n",
        "           (word_three not in word_to_index) or (word_four not in word_to_index):\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        # Get embeddings for the words\n",
        "        embedding_word_one = get_embedding(word_one, model, word_to_index)\n",
        "        embedding_word_two = get_embedding(word_two, model, word_to_index)\n",
        "        embedding_word_three = get_embedding(word_three, model, word_to_index)\n",
        "\n",
        "        # Compute the resulting analogy vector\n",
        "        result_embedding = embedding_word_two - embedding_word_one + embedding_word_three\n",
        "\n",
        "        # Find the top 10 nearest words to the result\n",
        "        predictions = get_k_nearest_words(10, result_embedding, model, word_to_index)\n",
        "\n",
        "        # Print detailed results\n",
        "        is_correct = word_four in predictions\n",
        "        print(f\"Analogy: {word_one} -> {word_two} :: {word_three} -> {word_four} | Prediction: {predictions}, Correct: {is_correct}\")\n",
        "\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    # Print final stats\n",
        "    print(f\"Total tasks skipped due to missing words: {skipped}\")\n",
        "    if total == 0:\n",
        "        print(\"No valid tasks were processed.\")\n",
        "        return 'No word was found in the embeddings'\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Analogy task accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Example usage: Test the model on a reduced subset for quick debugging\n",
        "accuracy = test_analogy(model, word_to_index, 'TestSet_sample.csv', subset_size=100)\n",
        "print(f\"Final Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWQ2vXQXxis8",
        "outputId": "81e01a06-847a-4de9-e2b6-d16dc7370909"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy: athens -> greece :: baghdad -> iraq | Prediction: ['baghdad', 'greece', 'iraq', 'kurdistan', 'afganistan', 'syria', 'Iraq.', 'israel', 'irak', 'syria.'], Correct: True\n",
            "Analogy: athens -> greece :: bangkok -> thailand | Prediction: ['bangkok', 'greece', 'thailand', 'italy', 'europe', 'hungary', 'spain', 'china.', 'france', 'Thailand.'], Correct: True\n",
            "Analogy: athens -> greece :: beijing -> china | Prediction: ['beijing', 'greece', 'china.', 'russia', 'xinjiang', 'taiwan', 'CHina', 'chinas', 'china', 'chinese'], Correct: True\n",
            "Analogy: athens -> greece :: berlin -> germany | Prediction: ['berlin', 'germany', 'greece', 'poland', 'france', 'europe', 'italy', 'russia', 'ww2', 'germany.'], Correct: True\n",
            "Analogy: athens -> greece :: bern -> switzerland | Prediction: ['bern', 'greece', 'slovenia', 'croatia', 'slovakia', 'france', 'israel', 'spain', 'denmark', 'italy'], Correct: False\n",
            "Analogy: athens -> greece :: cairo -> egypt | Prediction: ['cairo', 'greece', 'egypt', 'israel', 'ethiopia', 'jordan', 'syria', 'Eygpt', 'lebanon', 'italy'], Correct: True\n",
            "Analogy: athens -> greece :: canberra -> australia | Prediction: ['canberra', 'greece', 'australia', 'australia.', 'melbourne', 'australians', 'qld', 'bulgaria', 'sydney', 'slovakia'], Correct: True\n",
            "Analogy: athens -> greece :: hanoi -> vietnam | Prediction: ['greece', 'hanoi', 'italy', 'slovenia', 'france', 'chinas', 'turkey.', 'slovakia', 'fujian', 'ethiopia'], Correct: False\n",
            "Analogy: athens -> greece :: havana -> cuba | Prediction: ['havana', 'greece', 'cuba', 'spain', 'uruguay', 'france', 'italy', 'phillipines', 'russia', 'philipines'], Correct: True\n",
            "Analogy: athens -> greece :: helsinki -> finland | Prediction: ['greece', 'helsinki', 'finland', 'latvia', 'sweden', 'slovakia', 'bulgaria', 'slovenia', 'italy', 'scandinavia'], Correct: True\n",
            "Analogy: athens -> greece :: islamabad -> pakistan | Prediction: ['islamabad', 'pakistan', 'greece', 'peshawar', 'pakistan.', 'rawalpindi', 'sialkot', 'pakistans', 'lahore', 'amritsar'], Correct: True\n",
            "Analogy: athens -> greece :: kabul -> afghanistan | Prediction: ['kabul', 'greece', 'afganistan', 'afghanistan', 'afghanistan.', 'turkmenistan', 'afgan', 'pakistan', 'tajikistan', 'ethiopia'], Correct: True\n",
            "Analogy: athens -> greece :: london -> england | Prediction: ['london', 'greece', 'england', 'britain', 'uk', 'europe', 'france', 'spain', 'italy', 'africa'], Correct: True\n",
            "Analogy: athens -> greece :: madrid -> spain | Prediction: ['madrid', 'greece', 'spain', 'barca', 'ronaldo', 'athletico', 'barcelona', 'bayern', 'uruguay', 'messi'], Correct: True\n",
            "Analogy: athens -> greece :: moscow -> russia | Prediction: ['moscow', 'greece', 'russia', 'ukraine', 'ussr', 'russia.', 'Russia.', 'russians', 'israel', 'bulgaria'], Correct: True\n",
            "Analogy: athens -> greece :: oslo -> norway | Prediction: ['oslo', 'greece', 'israel', 'israel.', 'norway', 'sweden', 'slovakia', 'scandinavia', 'finland', 'palestine'], Correct: True\n",
            "Analogy: athens -> greece :: ottawa -> canada | Prediction: ['ottawa', 'canada', 'greece', 'saskatchewan', 'quebec', 'manitoba', 'alberta', 'calgary', 'canadians', 'montreal'], Correct: True\n",
            "Analogy: athens -> greece :: paris -> france | Prediction: ['paris', 'france', 'greece', 'britain', 'poland', 'europe', 'germany', 'spain', 'italy', 'israel'], Correct: True\n",
            "Analogy: athens -> greece :: rome -> italy | Prediction: ['rome', 'greece', 'italy', 'spain', 'europe', 'poland', 'christianity', 'romans', 'mesopotamia', 'france'], Correct: True\n",
            "Analogy: athens -> greece :: stockholm -> sweden | Prediction: ['stockholm', 'greece', 'sweden', 'scandinavia', 'italy', 'denmark', 'norway', 'slovakia', 'slovenia', 'latvia'], Correct: True\n",
            "Analogy: athens -> greece :: tehran -> iran | Prediction: ['tehran', 'greece', 'iran', 'iran.', 'Iran.', 'israel', 'turkmenistan', 'uzbekistan', 'baghdad', 'russia'], Correct: True\n",
            "Analogy: athens -> greece :: tokyo -> japan | Prediction: ['tokyo', 'japan', 'greece', 'japan.', 'italy', 'japanese', 'fukushima', 'asia', 'osaka', 'germany'], Correct: True\n",
            "Analogy: baghdad -> iraq :: bangkok -> thailand | Prediction: ['bangkok', 'iraq', 'thailand', 'vietnam', 'cambodia', 'australia', 'malaysia', 'tunisia', 'europe', 'afganistan'], Correct: True\n",
            "Analogy: baghdad -> iraq :: beijing -> china | Prediction: ['beijing', 'iraq', 'tibet', 'russia', 'vietnam', 'taiwan', 'israel', 'china', 'korea', 'australia'], Correct: True\n",
            "Analogy: baghdad -> iraq :: berlin -> germany | Prediction: ['berlin', 'iraq', 'germany', 'europe', 'russia', 'poland', 'france', 'ww2', 'israel', 'ussr'], Correct: True\n",
            "Analogy: baghdad -> iraq :: bern -> switzerland | Prediction: ['bern', 'iraq', 'afghanistan', 'clinton', 'israel', 'australia', 'denmark', 'kerry', 'iraq.', 'bolivia'], Correct: False\n",
            "Analogy: baghdad -> iraq :: cairo -> egypt | Prediction: ['cairo', 'iraq', 'egypt', 'israel', 'lebanon', 'syria', 'libya', 'tunisia', 'iran', 'isreal'], Correct: True\n",
            "Analogy: baghdad -> iraq :: canberra -> australia | Prediction: ['canberra', 'iraq', 'australia', 'australian', 'howard', 'sydney', 'tasmania', 'queensland', 'australians', 'aust'], Correct: True\n",
            "Analogy: baghdad -> iraq :: hanoi -> vietnam | Prediction: ['iraq', 'hanoi', 'vietnam', 'clinton', 'cambodia', 'iraq.', 'wmd', 'wolfowitz', 'kerry', 'murikka'], Correct: True\n",
            "Analogy: baghdad -> iraq :: havana -> cuba | Prediction: ['iraq', 'havana', 'vietnam', 'cuba', 'usa', 'america', 'bolivia', 'afghanistan', 'libya', 'mexico'], Correct: True\n",
            "Analogy: baghdad -> iraq :: helsinki -> finland | Prediction: ['helsinki', 'iraq', 'sweden', 'finland', 'afghanistan', 'denmark', 'vietnam', 'lebanon', 'norway', 'australia'], Correct: True\n",
            "Analogy: baghdad -> iraq :: islamabad -> pakistan | Prediction: ['iraq', 'pakistan', 'islamabad', 'afghanistan', 'iraq.', 'afganistan', 'afgan', 'karachi', 'bangladesh', 'peshawar'], Correct: True\n",
            "Analogy: baghdad -> iraq :: kabul -> afghanistan | Prediction: ['iraq', 'kabul', 'afghanistan', 'afganistan', 'Afganistan', 'iraq.', 'afgan', 'iran', 'pakistan', 'Irag'], Correct: True\n",
            "Analogy: baghdad -> iraq :: london -> england | Prediction: ['london', 'iraq', 'uk', 'england', 'europe', 'britain', 'america', 'africa', 'australia', 'israel'], Correct: True\n",
            "Analogy: baghdad -> iraq :: madrid -> spain | Prediction: ['madrid', 'iraq', 'barcelona', 'bayern', 'suarez', 'ronaldo', 'barca', 'atletico', 'spain', 'valencia'], Correct: True\n",
            "Analogy: baghdad -> iraq :: moscow -> russia | Prediction: ['moscow', 'iraq', 'russia', 'ussr', 'israel', 'ukraine', 'russians', 'iran', 'syria', 'chechnya'], Correct: True\n",
            "Analogy: baghdad -> iraq :: oslo -> norway | Prediction: ['oslo', 'iraq', 'israel', 'israel.', 'norway', 'israeli', 'sweden', 'lebanon', 'palestine', 'isreal'], Correct: True\n",
            "Analogy: baghdad -> iraq :: ottawa -> canada | Prediction: ['ottawa', 'iraq', 'canada', 'alberta', 'saskatchewan', 'montreal', 'manitoba', 'canadian', 'australia', 'canadians'], Correct: True\n",
            "Analogy: baghdad -> iraq :: paris -> france | Prediction: ['paris', 'iraq', 'france', 'europe', 'israel', 'africa', 'hilton', 'america', 'Paris', 'clinton'], Correct: True\n",
            "Analogy: baghdad -> iraq :: rome -> italy | Prediction: ['rome', 'iraq', 'greece', 'italy', 'europe', 'russia', 'clinton', 'israel', 'usa', 'syria'], Correct: True\n",
            "Analogy: baghdad -> iraq :: stockholm -> sweden | Prediction: ['stockholm', 'iraq', 'sweden', 'syndrom', 'denmark', 'australia', 'syndrome', 'norway', 'helsinki', 'america'], Correct: True\n",
            "Analogy: baghdad -> iraq :: tehran -> iran | Prediction: ['iraq', 'tehran', 'iran', 'afghanistan', 'lebanon', 'israel', 'syria', 'russia', 'iranian', 'pakistan'], Correct: True\n",
            "Analogy: baghdad -> iraq :: tokyo -> japan | Prediction: ['tokyo', 'iraq', 'japan', 'australia', 'korea', 'japan.', 'japanese', 'zealand', 'vietnam', 'usa'], Correct: True\n",
            "Analogy: baghdad -> iraq :: athens -> greece | Prediction: ['athens', 'iraq', 'greece', 'greeks', 'greek', 'australia', 'athenian', 'macedonia', 'egypt', 'sparta'], Correct: True\n",
            "Analogy: bangkok -> thailand :: beijing -> china | Prediction: ['beijing', 'thailand', 'tibet', 'hongkong', 'taiwan', 'mongolia', 'russia', 'china.', 'korea', 'singapore'], Correct: False\n",
            "Analogy: bangkok -> thailand :: berlin -> germany | Prediction: ['berlin', 'germany', 'thailand', 'germany.', 'russia', 'poland', 'europe', 'sweden', 'korea', 'france'], Correct: True\n",
            "Analogy: bangkok -> thailand :: bern -> switzerland | Prediction: ['bern', 'thailand', 'iceland', 'bolivia', 'sweden', 'honduras', 'england', 'denmark', 'switzerland', 'uruguay'], Correct: True\n",
            "Analogy: bangkok -> thailand :: cairo -> egypt | Prediction: ['cairo', 'egypt', 'thailand', 'tunisia', 'lebanon', 'opengl', 'bahrain', 'ethiopia', 'Eygpt', 'egyptian'], Correct: True\n",
            "Analogy: bangkok -> thailand :: canberra -> australia | Prediction: ['canberra', 'thailand', 'australia', 'australian', 'sydney', 'aust', 'nsw', 'tasmania', 'melbourne', 'queensland'], Correct: True\n",
            "Analogy: bangkok -> thailand :: hanoi -> vietnam | Prediction: ['hanoi', 'thailand', 'cambodia', 'indochina', 'vietnam', 'pisa', 'thais', 'korea', 'singapore', 'taipei'], Correct: True\n",
            "Analogy: bangkok -> thailand :: havana -> cuba | Prediction: ['havana', 'thailand', 'cuba', 'bolivia', 'honduras', 'uruguay', 'phillipines', 'colombia', 'nicaragua', 'bahamas'], Correct: True\n",
            "Analogy: bangkok -> thailand :: helsinki -> finland | Prediction: ['helsinki', 'thailand', 'finland', 'sweden', 'estonia', 'norway', 'iceland', 'azerbaijan', 'latvia', 'slovakia'], Correct: True\n",
            "Analogy: bangkok -> thailand :: islamabad -> pakistan | Prediction: ['islamabad', 'thailand', 'sialkot', 'lahore', 'peshawar', 'pakistan', 'multan', 'rawalpindi', 'quetta', 'karachi'], Correct: True\n",
            "Analogy: bangkok -> thailand :: kabul -> afghanistan | Prediction: ['kabul', 'thailand', 'afghanistan', 'afganistan', 'kandahar', 'peshawar', 'iran', 'tajikistan', 'turkmenistan', 'waziristan'], Correct: True\n",
            "Analogy: bangkok -> thailand :: london -> england | Prediction: ['london', 'thailand', 'england', 'uk', 'america', 'britain', 'birmingham', 'scotland', 'africa', 'england.'], Correct: True\n",
            "Analogy: bangkok -> thailand :: madrid -> spain | Prediction: ['madrid', 'barcelona', 'thailand', 'barca', 'atletico', 'ronaldo', 'bayern', 'valencia', 'uruguay', 'spain'], Correct: True\n",
            "Analogy: bangkok -> thailand :: moscow -> russia | Prediction: ['moscow', 'thailand', 'russia', 'ukraine', 'beijing', 'belarus', 'sochi', 'russia.', 'ussr', 'iran'], Correct: True\n",
            "Analogy: bangkok -> thailand :: oslo -> norway | Prediction: ['oslo', 'thailand', 'norway', 'sweden', 'finland', 'bærum', 'iceland', 'slovakia', 'ireland.', 'denmark'], Correct: True\n",
            "Analogy: bangkok -> thailand :: ottawa -> canada | Prediction: ['ottawa', 'saskatchewan', 'manitoba', 'canada', 'montreal', 'alberta', 'canadian', 'thailand', 'calgary', 'quebec'], Correct: True\n",
            "Analogy: bangkok -> thailand :: paris -> france | Prediction: ['paris', 'thailand', 'france', 'africa', 'ireland', 'america', 'london', 'sweden', 'belgium', 'hilton'], Correct: True\n",
            "Analogy: bangkok -> thailand :: rome -> italy | Prediction: ['rome', 'thailand', 'greece', 'italy', 'england', 'ireland', 'egypt', 'persia', 'russia', 'america'], Correct: True\n",
            "Analogy: bangkok -> thailand :: stockholm -> sweden | Prediction: ['stockholm', 'thailand', 'sweden', 'norway', 'helsinki', 'denmark', 'scandinavia', 'iceland', 'finland', 'scandinavian'], Correct: True\n",
            "Analogy: bangkok -> thailand :: tehran -> iran | Prediction: ['tehran', 'thailand', 'iran', 'tabriz', 'iran.', 'Iran.', 'bahrain', 'azerbaijan', 'tunisia', 'egypt'], Correct: True\n",
            "Analogy: bangkok -> thailand :: tokyo -> japan | Prediction: ['tokyo', 'thailand', 'japan', 'japan.', 'japanese', 'korea', 'singapore', 'seoul', 'osaka', 'okinawa'], Correct: True\n",
            "Analogy: bangkok -> thailand :: athens -> greece | Prediction: ['athens', 'thailand', 'greece', 'sparta', 'athenian', 'greek', 'egypt', 'Greece.', 'hellenic', 'aegean'], Correct: True\n",
            "Analogy: bangkok -> thailand :: baghdad -> iraq | Prediction: ['baghdad', 'thailand', 'iraq', 'kurdistan', 'kuwait', 'basra', 'bagdad', 'iran', 'afghanistan', 'afganistan'], Correct: True\n",
            "Analogy: beijing -> china :: berlin -> germany | Prediction: ['berlin', 'china', 'germany', 'Berlin', 'Germany', 'german', 'porcelain', 'europe', 'ww2', 'Germany.'], Correct: True\n",
            "Analogy: beijing -> china :: bern -> switzerland | Prediction: ['bern', 'china', 'delft', 'crockery', 'porcelain', 'redware', 'teacups', 'flintstone', 'teapot', 'rumpy'], Correct: False\n",
            "Analogy: beijing -> china :: cairo -> egypt | Prediction: ['cairo', 'china', 'egypt', 'morocco', 'delft', 'Eygpt', 'ware', 'emery', 'jewlery', 'Hispano-Moresque'], Correct: True\n",
            "Analogy: beijing -> china :: canberra -> australia | Prediction: ['canberra', 'china', 'queensland', 'aust', 'australian', 'australia', 'Vic.', 'crockery', 'Ausralia', 'downunder'], Correct: True\n",
            "Analogy: beijing -> china :: hanoi -> vietnam | Prediction: ['china', 'delft', 'porcelain', 'Fiestaware', 'treen', 'chinaware', 'redware', 'Lladró', 'teacups', 'hanoi'], Correct: False\n",
            "Analogy: beijing -> china :: havana -> cuba | Prediction: ['china', 'havana', 'calico', 'porcelain', 'Fiestaware', 'calicoes', 'chinaware', 'tortoise-shell', 'delft', 'wall-hangings'], Correct: False\n",
            "Analogy: beijing -> china :: helsinki -> finland | Prediction: ['china', 'helsinki', 'delft', 'crockery', 'sweden', 'antique', 'chinaware', 'porcelain', 'jewlery', 'ikea'], Correct: False\n",
            "Analogy: beijing -> china :: islamabad -> pakistan | Prediction: ['china', 'islamabad', 'pakistan', 'patiala', 'sargodha', 'peshawar', 'Bangladesh.', 'sialkot', 'sultanpur', 'rajkot'], Correct: True\n",
            "Analogy: beijing -> china :: kabul -> afghanistan | Prediction: ['kabul', 'china', 'Afganistan', 'afghanistan', 'Afghnistan', 'Afghanistan', 'Afghansitan', 'afganistan', 'afgan', 'afghans'], Correct: True\n",
            "Analogy: beijing -> china :: london -> england | Prediction: ['london', 'china', 'england', 'britain', 'uk', 'London', 'europe', 'cheshire', 'England', 'wales'], Correct: True\n",
            "Analogy: beijing -> china :: madrid -> spain | Prediction: ['madrid', 'china', 'spain', 'barcelona', 'barca', 'argentina', 'atletico', 'Spain', 'Madrid', 'portugal'], Correct: True\n",
            "Analogy: beijing -> china :: moscow -> russia | Prediction: ['china', 'moscow', 'russia', 'russian', 'usa', 'ussr', 'Russia.', 'soviet', 'russians', 'putin'], Correct: True\n",
            "Analogy: beijing -> china :: oslo -> norway | Prediction: ['china', 'oslo', 'germany', 'sweden', 'delft', 'iceland', 'tableware', 'porcelain', 'ireland.', 'countrys'], Correct: False\n",
            "Analogy: beijing -> china :: ottawa -> canada | Prediction: ['ottawa', 'china', 'canada', 'vermont', 'saskatchewan', 'calgary', 'alberta', 'canadian', 'manitoba', 'Canda'], Correct: True\n",
            "Analogy: beijing -> china :: paris -> france | Prediction: ['paris', 'china', 'plaster', 'Paris', 'porcelain', 'France', 'france', 'louis', 'pink', 'french'], Correct: True\n",
            "Analogy: beijing -> china :: rome -> italy | Prediction: ['rome', 'china', 'Rome', 'greece', 'italy', 'england', 'europe', 'usa', 'germany', 'romans'], Correct: True\n",
            "Analogy: beijing -> china :: stockholm -> sweden | Prediction: ['stockholm', 'china', 'syndrom', 'porcelain', 'sweden', 'syndrome', 'delft', 'Gustavsberg', 'calico', 'gollywog'], Correct: True\n",
            "Analogy: beijing -> china :: tehran -> iran | Prediction: ['china', 'tehran', 'iran', 'tabriz', 'Iran.', 'Iran', 'velvets', 'delft', 'persian', 'europe'], Correct: True\n",
            "Analogy: beijing -> china :: tokyo -> japan | Prediction: ['china', 'tokyo', 'japan', 'japanese', 'crockery', 'Japan', 'teacups', 'porcelain', 'chinaware', 'japan.'], Correct: True\n",
            "Analogy: beijing -> china :: athens -> greece | Prediction: ['athens', 'china', 'parthenon', 'greece', 'elgin', 'greek', 'Parthenon', 'Mycenae', 'Greece', 'Greece.'], Correct: True\n",
            "Analogy: beijing -> china :: baghdad -> iraq | Prediction: ['china', 'baghdad', 'iraq', 'Iraq', 'Afghnistan', 'Afghanastan', 'Iraq.', 'afghanistan', 'america', 'bagdad'], Correct: True\n",
            "Analogy: beijing -> china :: bangkok -> thailand | Prediction: ['china', 'bangkok', 'crockery', 'chinaware', 'porcelain', 'Thailand', 'delft', 'teacups', 'thailand', 'furniture'], Correct: True\n",
            "Analogy: berlin -> germany :: bern -> switzerland | Prediction: ['bern', 'germany', 'england', 'denmark', 'switzerland', 'bothered.', 'spain.', 'germany.', 'paraguay', 'uruguay'], Correct: True\n",
            "Analogy: berlin -> germany :: cairo -> egypt | Prediction: ['cairo', 'germany', 'egypt', 'iran', 'israel', 'saudia', 'syria', 'greece', 'tunisia', 'spain'], Correct: True\n",
            "Analogy: berlin -> germany :: canberra -> australia | Prediction: ['canberra', 'australia', 'australian', 'nsw', 'queensland', 'australia.', 'germany', 'Aust.', 'Ausralia', 'Australia-'], Correct: True\n",
            "Analogy: berlin -> germany :: hanoi -> vietnam | Prediction: ['germany', 'hanoi', 'spain.', 'england', 'paraguay', 'germany.', 'andorra', 'portugal', 'southamerica', 'america'], Correct: False\n",
            "Analogy: berlin -> germany :: havana -> cuba | Prediction: ['havana', 'germany', 'uruguay', 'spain', 'usa', 'spain.', 'america', 'paraguay', 'caribean', 'phillipines'], Correct: False\n",
            "Analogy: berlin -> germany :: helsinki -> finland | Prediction: ['helsinki', 'germany', 'sweden', 'finland', 'denmark', 'paraguay', 'austria', 'slovakia', 'croatia', 'scandinavia'], Correct: True\n",
            "Analogy: berlin -> germany :: islamabad -> pakistan | Prediction: ['islamabad', 'pakistan', 'sialkot', 'peshawar', 'pakistan.', 'rawalpindi', 'pakistans', 'lahore', 'faisalabad', 'multan'], Correct: True\n",
            "Analogy: berlin -> germany :: kabul -> afghanistan | Prediction: ['kabul', 'germany', 'afganistan', 'afghanistan', 'iran', 'afghanistan.', 'pakistan', 'pakistan.', 'afgan', 'america'], Correct: True\n",
            "Analogy: berlin -> germany :: london -> england | Prediction: ['london', 'england', 'germany', 'europe', 'uk', 'britain', 'america', 'spain', 'france', 'wales'], Correct: True\n",
            "Analogy: berlin -> germany :: madrid -> spain | Prediction: ['madrid', 'barca', 'spain', 'bayern', 'barcelona', 'athletico', 'atletico', 'ronaldo', 'germany', 'portugal'], Correct: True\n",
            "Analogy: berlin -> germany :: moscow -> russia | Prediction: ['moscow', 'russia', 'germany', 'ukraine', 'russia.', 'iran', 'europe', 'usa', 'ussr', 'america'], Correct: True\n",
            "Analogy: berlin -> germany :: oslo -> norway | Prediction: ['oslo', 'germany', 'sweden', 'norway', 'denmark', 'spain.', 'germany.', 'scandinavia', 'israel', 'finland'], Correct: True\n",
            "Total tasks skipped due to missing words: 0\n",
            "Analogy task accuracy: 0.8900\n",
            "Final Accuracy: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(word, model, word_to_index):\n",
        "    \"\"\"Retrieve the embedding for a given word.\"\"\"\n",
        "    return model[word]\n",
        "\n",
        "def get_k_nearest_words(k, result_embedding, model, word_to_index):\n",
        "    \"\"\"Find the k nearest words to the given embedding.\"\"\"\n",
        "    most_similar = model.similar_by_vector(result_embedding, topn=k)\n",
        "    return [word for word, _ in most_similar]\n",
        "\n",
        "def test_analogy(model, word_to_index, analogy_file, subset_size=None):\n",
        "    \"\"\"\n",
        "    Method to test accuracy of embeddings on analogy tasks.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    model : KeyedVectors\n",
        "        Trained word embeddings model.\n",
        "    word_to_index : Dictionary\n",
        "        Dictionary mapping words to indices {word: index}.\n",
        "    analogy_file : String\n",
        "        File containing analogy tasks.\n",
        "    subset_size : int, optional\n",
        "        Number of rows to use from the dataset (for testing purposes).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    accuracy : float\n",
        "        Accuracy of the model on the analogy tasks.\n",
        "    \"\"\"\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(analogy_file)\n",
        "\n",
        "    # Filter by the 'capital-common-countries' category\n",
        "    df = df[df['category'] == 'family']\n",
        "\n",
        "    # Reduce the dataset size for testing, if subset_size is provided\n",
        "    if subset_size:\n",
        "        df = df.head(subset_size)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    skipped = 0  # Counter for skipped tasks\n",
        "\n",
        "    # Iterate through each analogy task\n",
        "    for index, row in df.iterrows():\n",
        "        word_one = row['word_one'].lower()\n",
        "        word_two = row['word_two'].lower()\n",
        "        word_three = row['word_three'].lower()\n",
        "        word_four = row['word_four'].lower()\n",
        "\n",
        "        # Skip tasks if any word is not in the vocabulary\n",
        "        if (word_one not in word_to_index) or (word_two not in word_to_index) or \\\n",
        "           (word_three not in word_to_index) or (word_four not in word_to_index):\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        # Get embeddings for the words\n",
        "        embedding_word_one = get_embedding(word_one, model, word_to_index)\n",
        "        embedding_word_two = get_embedding(word_two, model, word_to_index)\n",
        "        embedding_word_three = get_embedding(word_three, model, word_to_index)\n",
        "\n",
        "        # Compute the resulting analogy vector\n",
        "        result_embedding = embedding_word_two - embedding_word_one + embedding_word_three\n",
        "\n",
        "        # Find the top 10 nearest words to the result\n",
        "        predictions = get_k_nearest_words(10, result_embedding, model, word_to_index)\n",
        "\n",
        "        # Print detailed results\n",
        "        is_correct = word_four in predictions\n",
        "        print(f\"Analogy: {word_one} -> {word_two} :: {word_three} -> {word_four} | Prediction: {predictions}, Correct: {is_correct}\")\n",
        "\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    # Print final stats\n",
        "    print(f\"Total tasks skipped due to missing words: {skipped}\")\n",
        "    if total == 0:\n",
        "        print(\"No valid tasks were processed.\")\n",
        "        return 'No word was found in the embeddings'\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Analogy task accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Example usage: Test the model on a reduced subset for quick debugging\n",
        "accuracy = test_analogy(model, word_to_index, 'TestSet_sample.csv', subset_size=100)\n",
        "print(f\"Final Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3ttZfL4CI6L",
        "outputId": "c013f3d2-0bdc-42bb-dae7-fa0932581b43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy: boy -> girl :: brother -> sister | Prediction: ['brother', 'sister', 'cousin', 'sister-in-law', 'brother-in-law', 'niece', 'sisters', 'nephew', 'uncle', 'half-brother'], Correct: True\n",
            "Analogy: boy -> girl :: brothers -> sisters | Prediction: ['brothers', 'sisters', 'brother', 'siblings', 'Brothers', 'cousins', 'sister', 'sisters-in-law', 'husbands', 'Sisters'], Correct: True\n",
            "Analogy: boy -> girl :: dad -> mom | Prediction: ['dad', 'mom', 'mum', 'stepdad', 'grandma', 'stepmom', 'mother', 'step-dad', 'step-mom', 'boyfriend'], Correct: True\n",
            "Analogy: boy -> girl :: father -> mother | Prediction: ['father', 'mother', 'husband', 'daughter', 'grandmother', 'wife', 'grandfather', 'ex-husband', 'brother', 'boyfriend'], Correct: True\n",
            "Analogy: boy -> girl :: grandfather -> grandmother | Prediction: ['grandfather', 'grandmother', 'granddaughter', 'great-grandfather', 'uncle', 'aunt', 'great-grandmother', 'grandson', 'niece', 'father'], Correct: True\n",
            "Analogy: boy -> girl :: grandpa -> grandma | Prediction: ['grandpa', 'grandma', 'granny', 'grandmother', 'Grandma', 'granddad', 'Grandpa', 'grandad', 'great-grandma', 'mom'], Correct: True\n",
            "Analogy: boy -> girl :: grandson -> granddaughter | Prediction: ['granddaughter', 'grandson', 'daughter', 'niece', 'great-grandson', 'great-granddaughter', 'grandfather', 'grandchild', 'daughter-in-law', 'nephew'], Correct: True\n",
            "Analogy: boy -> girl :: groom -> bride | Prediction: ['groom', 'bride', 'grooms', 'bridegroom', 'brides', 'bridesmaids', 'bride-to-be', 'bridesmaid', 'bridegrooms', 'bridal'], Correct: True\n",
            "Analogy: boy -> girl :: he -> she | Prediction: ['she', 'he', 'they', 'shes', '--she', 'herself', 'SHe', 'nobody', 'it.She', 'her'], Correct: True\n",
            "Analogy: boy -> girl :: his -> her | Prediction: ['her', 'his', 'their', '-his', '--her', 'hers', 'my', 'its', 'beauty-queen', 'ofher'], Correct: True\n",
            "Analogy: boy -> girl :: husband -> wife | Prediction: ['husband', 'wife', 'husbands', 'ex-husband', 'spouse', 'mother-in-law', 'boyfriend', 'woman', 'fiance', 'daughter'], Correct: True\n",
            "Analogy: boy -> girl :: king -> queen | Prediction: ['king', 'queen', 'kings', 'princess', 'monarch', 'kingdom', 'prince', 'King', 'lady', 'queens'], Correct: True\n",
            "Analogy: boy -> girl :: man -> woman | Prediction: ['man', 'woman', 'girl', 'lady', 'men', 'woman.', 'women', 'guy', 'person', 'Woman'], Correct: True\n",
            "Analogy: boy -> girl :: nephew -> niece | Prediction: ['niece', 'nephew', 'cousin', 'brother-in-law', 'sister-in-law', 'uncle', 'brother', 'aunt', 'granddaughter', 'sister'], Correct: True\n",
            "Analogy: boy -> girl :: policeman -> policewoman | Prediction: ['policeman', 'policewoman', 'policemen', 'cop', 'Policeman', 'police', 'cops', 'woman', 'constable', 'lady'], Correct: True\n",
            "Analogy: boy -> girl :: prince -> princess | Prediction: ['prince', 'princess', 'princes', 'princesses', 'Princess', 'Prince', 'lady', 'girl', 'principality', 'duchess'], Correct: True\n",
            "Analogy: boy -> girl :: son -> daughter | Prediction: ['daughter', 'son', 'wife', 'husband', 'granddaughter', 'daughters', 'mother', 'niece', 'daughter-in-law', 'grandson'], Correct: True\n",
            "Analogy: boy -> girl :: sons -> daughters | Prediction: ['daughters', 'sons', 'daughter', 'husbands', 'wives', 'grandsons', 'wife', 'granddaughters', 'grandchildren', 'sisters'], Correct: True\n",
            "Analogy: boy -> girl :: stepbrother -> stepsister | Prediction: ['stepbrother', 'stepsister', 'step-brother', 'stepmother', 'boyfriend', 'step-mother', 'step-sister', 'stepfather', 'half-sister', 'ex-boyfriend'], Correct: True\n",
            "Analogy: boy -> girl :: stepfather -> stepmother | Prediction: ['stepfather', 'step-father', 'stepmother', 'ex-husband', 'boyfriend', 'mother', 'step-mother', 'ex-wife', 'grandmother', 'aunt'], Correct: True\n",
            "Analogy: boy -> girl :: stepson -> stepdaughter | Prediction: ['stepson', 'stepdaughter', 'niece', 'ex-husband', 'ex-wife', 'step-daughter', 'daughter', 'husband', 'step-son', 'wife'], Correct: True\n",
            "Analogy: boy -> girl :: uncle -> aunt | Prediction: ['uncle', 'aunt', 'niece', 'cousin', 'nephew', 'brother-in-law', 'grandmother', 'brother', 'sister-in-law', 'uncles'], Correct: True\n",
            "Analogy: brother -> sister :: brothers -> sisters | Prediction: ['sisters', 'brothers', 'sister', 'siblings', 'cousins', 'Brothers', 'twins', 'daughters', 'Sisters', 'brother'], Correct: True\n",
            "Analogy: brother -> sister :: dad -> mom | Prediction: ['dad', 'mum', 'mom', 'mother', 'Dad', 'step-dad', 'stepdad', 'step-mom', 'grandma', 'stepmom'], Correct: True\n",
            "Analogy: brother -> sister :: father -> mother | Prediction: ['mother', 'father', 'sister', 'daughter', 'grandmother', 'grandfather', 'son', 'dad', 'granddaughter', 'aunt'], Correct: True\n",
            "Analogy: brother -> sister :: grandfather -> grandmother | Prediction: ['grandfather', 'grandmother', 'granddaughter', 'sister', 'aunt', 'great-grandmother', 'grandson', 'great-grandfather', 'uncle', 'great-great-great-great'], Correct: True\n",
            "Analogy: brother -> sister :: grandpa -> grandma | Prediction: ['grandpa', 'grandma', 'granny', 'grandmother', 'Grandma', 'Grandpa', 'granddad', 'auntie', 'grandad', 'grandkids'], Correct: True\n",
            "Analogy: brother -> sister :: grandson -> granddaughter | Prediction: ['granddaughter', 'grandson', 'daughter', 'great-grandson', 'great-granddaughter', 'grand-daughter', 'niece', 'grandchild', 'grandfather', 'sister'], Correct: True\n",
            "Analogy: brother -> sister :: groom -> bride | Prediction: ['groom', 'grooms', 'bride', 'bridegroom', 'bridal', 'bridesmaid', 'bridesmaids', 'brides', 'wedding', 'marry'], Correct: True\n",
            "Analogy: brother -> sister :: he -> she | Prediction: ['he', 'she', 'they', 'additionally', 'SHe', 'nobody', 'subsequently', 'clearly', 'which', 'also'], Correct: True\n",
            "Analogy: brother -> sister :: his -> her | Prediction: ['his', 'her', 'their', 'its', 'own', 'several', 'various', '-his', 'numerous', 'two'], Correct: True\n",
            "Analogy: brother -> sister :: husband -> wife | Prediction: ['husband', 'wife', 'daughter', 'mother-in-law', 'sister', 'daughter-in-law', 'mother', 'her', 'sister-in-law', 'spouse'], Correct: True\n",
            "Analogy: brother -> sister :: king -> queen | Prediction: ['king', 'queen', 'kings', 'princess', 'royal', 'monarch', 'kingdom', 'King', 'queens', 'uncrowned'], Correct: True\n",
            "Analogy: brother -> sister :: man -> woman | Prediction: ['man', 'woman', 'lady', 'girl', 'Woman', 'woman.', 'men', 'blonde', 'man-like', 'women'], Correct: True\n",
            "Analogy: brother -> sister :: nephew -> niece | Prediction: ['niece', 'nephew', 'sister', 'cousin', 'granddaughter', 'aunt', 'sister-in-law', 'uncle', 'daughter', 'brother-in-law'], Correct: True\n",
            "Analogy: brother -> sister :: policeman -> policewoman | Prediction: ['policeman', 'policewoman', 'policemen', 'cop', 'police', 'Policeman', 'cops', 'detective', 'coppers', 'constable'], Correct: True\n",
            "Analogy: brother -> sister :: prince -> princess | Prediction: ['prince', 'princess', 'princes', 'Princess', 'princesses', 'Prince', 'royal', 'principality', 'duchess', 'Princesses'], Correct: True\n",
            "Analogy: brother -> sister :: son -> daughter | Prediction: ['daughter', 'son', 'granddaughter', 'sister', 'mother', 'daughters', 'wife', 'grandson', 'niece', 'daughter-in-law'], Correct: True\n",
            "Analogy: brother -> sister :: sons -> daughters | Prediction: ['daughters', 'sons', 'daughter', 'sister', 'grand-daughters', 'granddaughters', 'grandsons', 'grandchildren', 'children', 'son'], Correct: True\n",
            "Analogy: brother -> sister :: stepbrother -> stepsister | Prediction: ['stepbrother', 'stepsister', 'sister', 'step-brother', 'stepmother', 'step-sister', 'half-sister', 'step-mother', 'stepfather', 'stepsiblings'], Correct: True\n",
            "Analogy: brother -> sister :: stepfather -> stepmother | Prediction: ['stepfather', 'step-father', 'stepmother', 'mother', 'step-mother', 'grandmother', 'sister', 'aunt', 'half-sister', 'stepsister'], Correct: True\n",
            "Analogy: brother -> sister :: stepson -> stepdaughter | Prediction: ['stepson', 'stepdaughter', 'daughter', 'niece', 'sister', 'step-son', 'granddaughter', 'step-daughter', 'stepmother', 'half-sister'], Correct: True\n",
            "Analogy: brother -> sister :: uncle -> aunt | Prediction: ['aunt', 'uncle', 'sister', 'niece', 'grandmother', 'cousin', 'grandfather', 'nephew', 'aunts', 'sister-in-law'], Correct: True\n",
            "Analogy: brother -> sister :: boy -> girl | Prediction: ['boy', 'girl', 'boys', 'lad', '12-year-old', 'child', 'girls', '14-year-old', 'kid', '13-year-old'], Correct: True\n",
            "Analogy: brothers -> sisters :: dad -> mom | Prediction: ['dad', 'mum', 'mom', 'mother', 'grandma', 'stepdad', 'grandmother', 'Mom', 'Dad', 'step-dad'], Correct: True\n",
            "Analogy: brothers -> sisters :: father -> mother | Prediction: ['mother', 'father', 'grandmother', 'daughter', 'aunt', 'dad', 'sister', 'sisters', 'mom', 'stepmother'], Correct: True\n",
            "Analogy: brothers -> sisters :: grandfather -> grandmother | Prediction: ['grandmother', 'grandfather', 'aunt', 'granddaughter', 'great-grandmother', 'uncle', 'mother', 'great-aunt', 'grandparents', 'niece'], Correct: True\n",
            "Analogy: brothers -> sisters :: grandpa -> grandma | Prediction: ['grandpa', 'grandma', 'grandmother', 'granny', 'Grandma', 'auntie', 'Grandmother', 'granddad', 'grandad', 'Grandpa'], Correct: True\n",
            "Analogy: brothers -> sisters :: grandson -> granddaughter | Prediction: ['granddaughter', 'grandson', 'grandmother', 'niece', 'daughter', 'grandchild', 'great-granddaughter', 'grand-daughter', 'great-grandson', 'granddaughters'], Correct: True\n",
            "Analogy: brothers -> sisters :: groom -> bride | Prediction: ['groom', 'bride', 'grooms', 'bridegroom', 'bridesmaids', 'bridesmaid', 'brides', 'bride-to-be', 'bridal', 'wedding'], Correct: True\n",
            "Analogy: brothers -> sisters :: he -> she | Prediction: ['he', 'she', 'SHe', '--she', 'they', '-she', 'her', 'shes', 'it', 'nobody'], Correct: True\n",
            "Analogy: brothers -> sisters :: his -> her | Prediction: ['his', 'her', '--her', 'their', '-his', 'my', 'its', 'ofher', 'hers', 'life.She'], Correct: True\n",
            "Analogy: brothers -> sisters :: husband -> wife | Prediction: ['husband', 'wife', 'mother-in-law', 'husbands', 'mother', 'daughter', 'her', 'spouse', 'sister-in-law', 'woman'], Correct: True\n",
            "Analogy: brothers -> sisters :: king -> queen | Prediction: ['king', 'queen', 'monarch', 'princess', 'kings', 'queens', 'lady', 'royal', 'Queen', 'prince'], Correct: True\n",
            "Analogy: brothers -> sisters :: man -> woman | Prediction: ['man', 'woman', 'lady', 'girl', 'Woman', 'woman.', 'men', 'women', 'ladies', 'person'], Correct: True\n",
            "Analogy: brothers -> sisters :: nephew -> niece | Prediction: ['niece', 'nephew', 'aunt', 'sister-in-law', 'sister', 'nieces', 'uncle', 'granddaughter', 'cousin', 'grandmother'], Correct: True\n",
            "Analogy: brothers -> sisters :: policeman -> policewoman | Prediction: ['policeman', 'policewoman', 'policemen', 'cop', 'Policeman', 'police', 'cops', 'policewomen', 'lady', 'constable'], Correct: True\n",
            "Analogy: brothers -> sisters :: prince -> princess | Prediction: ['prince', 'princess', 'princes', 'princesses', 'Princess', 'Prince', 'lady', 'duchess', 'queen', 'Princesses'], Correct: True\n",
            "Analogy: brothers -> sisters :: son -> daughter | Prediction: ['daughter', 'son', 'mother', 'granddaughter', 'daughters', 'niece', 'wife', 'eldest', 'grandmother', 'father'], Correct: True\n",
            "Analogy: brothers -> sisters :: sons -> daughters | Prediction: ['daughters', 'sons', 'sisters', 'daughter', 'granddaughters', 'grandchildren', 'wives', 'children', 'eldest', 'nieces'], Correct: True\n",
            "Analogy: brothers -> sisters :: stepbrother -> stepsister | Prediction: ['stepbrother', 'stepsister', 'stepmother', 'step-mother', 'step-sister', 'step-brother', 'half-sister', 'aunt', 'stepfather', 'sister'], Correct: True\n",
            "Analogy: brothers -> sisters :: stepfather -> stepmother | Prediction: ['stepfather', 'stepmother', 'step-father', 'mother', 'grandmother', 'aunt', 'step-mother', 'stepdad', 'half-sister', 'stepsister'], Correct: True\n",
            "Analogy: brothers -> sisters :: stepson -> stepdaughter | Prediction: ['stepson', 'stepdaughter', 'niece', 'step-son', 'daughter', 'stepmother', 'granddaughter', 'stepfather', 'step-daughter', 'half-sister'], Correct: True\n",
            "Analogy: brothers -> sisters :: uncle -> aunt | Prediction: ['aunt', 'uncle', 'niece', 'grandmother', 'aunts', 'sister', 'cousin', 'nephew', 'auntie', 'sister-in-law'], Correct: True\n",
            "Analogy: brothers -> sisters :: boy -> girl | Prediction: ['girl', 'boy', 'girls', 'boys', 'teenager', 'kid', 'girl-', 'schoolgirl', 'lad', 'child'], Correct: True\n",
            "Analogy: brothers -> sisters :: brother -> sister | Prediction: ['sister', 'brother', 'sisters', 'sister-in-law', 'niece', 'aunt', 'cousin', 'mother', 'uncle', 'grandmother'], Correct: True\n",
            "Analogy: dad -> mom :: father -> mother | Prediction: ['mother', 'father', 'mom', 'daughter', 'son', 'grandmother', 'brother', 'husband', 'stepfather', 'child'], Correct: True\n",
            "Analogy: dad -> mom :: grandfather -> grandmother | Prediction: ['grandfather', 'grandmother', 'grandson', 'granddaughter', 'mother', 'uncle', 'father', 'great-grandfather', 'great-grandmother', 'aunt'], Correct: True\n",
            "Analogy: dad -> mom :: grandpa -> grandma | Prediction: ['grandpa', 'grandma', 'mom', 'Grandma', 'grandmother', 'granny', 'Mom', 'grandkids', 'grandmom', 'Grandpa'], Correct: True\n",
            "Analogy: dad -> mom :: grandson -> granddaughter | Prediction: ['grandson', 'granddaughter', 'daughter', 'great-grandson', 'grandchild', 'son', 'great-granddaughter', 'daughter-in-law', 'grandsons', 'nephew'], Correct: True\n",
            "Analogy: dad -> mom :: groom -> bride | Prediction: ['groom', 'grooms', 'bride', 'bridegroom', 'brides', 'bridal', 'bridesmaids', 'groomsman', 'wedding', 'girl'], Correct: True\n",
            "Analogy: dad -> mom :: he -> she | Prediction: ['he', 'she', 'they', 'nobody', 'someone', '-He', 'everyone', 'we', '--she', 'him--he'], Correct: True\n",
            "Analogy: dad -> mom :: his -> her | Prediction: ['his', 'her', 'their', '-his', 'my', 'mom', '--her', 'its', '-His', 'aforementioned'], Correct: True\n",
            "Analogy: dad -> mom :: husband -> wife | Prediction: ['husband', 'wife', 'mother-in-law', 'daughter', 'spouse', 'mother', 'mom', 'daughter-in-law', 'woman', 'ex-husband'], Correct: True\n",
            "Analogy: dad -> mom :: king -> queen | Prediction: ['king', 'queen', 'kings', 'princess', 'monarch', 'kingdom', 'King', 'prince', 'queens', 'royal'], Correct: True\n",
            "Analogy: dad -> mom :: man -> woman | Prediction: ['man', 'woman', 'girl', 'lady', 'men', 'person', 'guy', 'boy', 'mom', 'women'], Correct: True\n",
            "Analogy: dad -> mom :: nephew -> niece | Prediction: ['nephew', 'niece', 'cousin', 'brother', 'sister-in-law', 'uncle', 'grandson', 'brother-in-law', 'granddaughter', 'aunt'], Correct: True\n",
            "Analogy: dad -> mom :: policeman -> policewoman | Prediction: ['policeman', 'policemen', 'policewoman', 'cop', 'Policeman', 'cops', 'police', 'patrolman', 'soldier', 'detective'], Correct: True\n",
            "Analogy: dad -> mom :: prince -> princess | Prediction: ['prince', 'princess', 'princes', 'princesses', 'Prince', 'Princess', 'king', 'kingdom', 'principality', 'queen'], Correct: True\n",
            "Analogy: dad -> mom :: son -> daughter | Prediction: ['son', 'daughter', 'mom', 'mother', 'grandson', 'granddaughter', 'sons', 'daughter-in-law', 'daughters', 'eldest'], Correct: True\n",
            "Analogy: dad -> mom :: sons -> daughters | Prediction: ['sons', 'daughters', 'daughter', 'son', 'grandsons', 'children', 'eldest', 'grandchildren', 'mom', 'mother'], Correct: True\n",
            "Analogy: dad -> mom :: stepbrother -> stepsister | Prediction: ['stepbrother', 'stepsister', 'step-brother', 'stepmother', 'stepfather', 'step-sister', 'stepdaughter', 'mom', 'step-mother', 'stepbrothers'], Correct: True\n",
            "Analogy: dad -> mom :: stepfather -> stepmother | Prediction: ['stepfather', 'step-father', 'mother', 'stepmother', 'mom', 'grandmother', 'aunt', 'stepdaughter', 'step-mother', 'ex-husband'], Correct: True\n",
            "Analogy: dad -> mom :: stepson -> stepdaughter | Prediction: ['stepson', 'stepdaughter', 'daughter', 'step-son', 'niece', 'stepfather', 'son', 'granddaughter', 'mom', 'nephew'], Correct: True\n",
            "Analogy: dad -> mom :: uncle -> aunt | Prediction: ['uncle', 'aunt', 'nephew', 'niece', 'grandmother', 'cousin', 'brother', 'sister-in-law', 'grandfather', 'brother-in-law'], Correct: True\n",
            "Analogy: dad -> mom :: boy -> girl | Prediction: ['boy', 'girl', 'kid', 'mom', 'boys', 'child', 'girls', 'teenager', 'teen', 'baby'], Correct: True\n",
            "Analogy: dad -> mom :: brother -> sister | Prediction: ['brother', 'sister', 'sister-in-law', 'cousin', 'nephew', 'brother-in-law', 'mom', 'mother', 'niece', 'daughter'], Correct: True\n",
            "Analogy: dad -> mom :: brothers -> sisters | Prediction: ['brothers', 'sisters', 'siblings', 'brother', 'Brothers', 'sons', 'twins', 'cousins', 'brethren', 'sister'], Correct: True\n",
            "Analogy: father -> mother :: grandfather -> grandmother | Prediction: ['grandmother', 'grandfather', 'mother', 'aunt', 'granddaughter', 'uncle', 'grandson', 'grandparents', 'great-grandmother', 'father'], Correct: True\n",
            "Analogy: father -> mother :: grandpa -> grandma | Prediction: ['grandpa', 'grandma', 'grandmother', 'granny', 'Grandma', 'mom', 'Grandmother', 'Grandpa', 'grampa', 'granddad'], Correct: True\n",
            "Analogy: father -> mother :: grandson -> granddaughter | Prediction: ['grandson', 'granddaughter', 'daughter', 'grandchild', 'grandmother', 'mother', 'great-grandson', 'son', 'niece', 'daughter-in-law'], Correct: True\n",
            "Analogy: father -> mother :: groom -> bride | Prediction: ['groom', 'grooms', 'bride', 'bridegroom', 'brides', 'bridesmaids', 'bridesmaid', 'bridal', 'bride-to-be', 'groomsman'], Correct: True\n",
            "Analogy: father -> mother :: he -> she | Prediction: ['he', 'she', 'they', 'nobody', 'there', 'someone', 'SHe', 'it', '.He', '-He'], Correct: True\n",
            "Analogy: father -> mother :: his -> her | Prediction: ['his', 'her', 'their', '-his', 'its', 'my', 'mother', 'own', 'entire', 'full'], Correct: True\n",
            "Analogy: father -> mother :: husband -> wife | Prediction: ['husband', 'wife', 'mother', 'mother-in-law', 'daughter', 'spouse', 'husbands', 'daughter-in-law', 'woman', 'sister-in-law'], Correct: True\n",
            "Analogy: father -> mother :: king -> queen | Prediction: ['king', 'queen', 'kings', 'monarch', 'princess', 'kingdom', 'royal', 'King', 'queens', 'prince'], Correct: True\n",
            "Analogy: father -> mother :: man -> woman | Prediction: ['man', 'woman', 'girl', 'lady', 'men', 'person', 'fella', 'guy', 'boy', 'Woman'], Correct: True\n",
            "Analogy: father -> mother :: nephew -> niece | Prediction: ['nephew', 'niece', 'sister-in-law', 'aunt', 'cousin', 'uncle', 'brother', 'brother-in-law', 'sister', 'grandmother'], Correct: True\n",
            "Analogy: father -> mother :: policeman -> policewoman | Prediction: ['policeman', 'policemen', 'policewoman', 'cop', 'Policeman', 'cops', 'police', 'Policemen', 'coppers', 'fireman'], Correct: True\n",
            "Analogy: father -> mother :: prince -> princess | Prediction: ['prince', 'princess', 'princes', 'Prince', 'Princess', 'princesses', 'king', 'duchess', 'queen', 'royal'], Correct: True\n",
            "Total tasks skipped due to missing words: 0\n",
            "Analogy task accuracy: 1.0000\n",
            "Final Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go  # <-- Make sure this import is here\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word_to_index = {word: idx for idx, word in enumerate(model.index_to_key)}\n",
        "\n",
        "# Step 2: Load the analogy dataset\n",
        "analogy_df = pd.read_csv('TestSet_sample.csv')\n",
        "\n",
        "# Step 3: Extract words by category\n",
        "def extract_words_by_category(df, category):\n",
        "    words = set(df[df['category'] == category][['word_one', 'word_two', 'word_three', 'word_four']].values.flatten())\n",
        "    words = [word.lower() for word in words if word.lower() in word_to_index]\n",
        "    return words\n",
        "\n",
        "family_words = extract_words_by_category(analogy_df, 'family')\n",
        "capital_words = extract_words_by_category(analogy_df, 'capital-common-countries')\n",
        "\n",
        "# Debugging: Print unmatched words\n",
        "unmatched_family = [word for word in family_words if word not in word_to_index]\n",
        "unmatched_capital = [word for word in capital_words if word not in word_to_index]\n",
        "print(f\"Unmatched family words: {unmatched_family}\")\n",
        "print(f\"Unmatched capital words: {unmatched_capital}\")\n",
        "\n",
        "# Ensure categories are not empty\n",
        "if not family_words or not capital_words:\n",
        "    raise ValueError(\"One of the categories has no valid words in the vocabulary.\")\n",
        "\n",
        "# Step 4: Extract embeddings for each category\n",
        "def get_embeddings_for_words(words):\n",
        "    return np.array([model[word] for word in words])\n",
        "\n",
        "family_embeddings = get_embeddings_for_words(family_words)\n",
        "capital_embeddings = get_embeddings_for_words(capital_words)\n",
        "\n",
        "# Combine all embeddings and labels\n",
        "all_embeddings = np.vstack([family_embeddings, capital_embeddings])\n",
        "all_labels = family_words + capital_words\n",
        "\n",
        "# Step 5: Apply t-SNE on the combined embeddings\n",
        "print(\"Running t-SNE...\")\n",
        "tsne = TSNE(n_components=2, random_state=0, perplexity=30)\n",
        "reduced_embeddings = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Step 6: Create a scatter plot using Plotly with color-coding by category\n",
        "colors = ['blue'] * len(family_words) + ['green'] * len(capital_words)  # Assign colors based on category\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add scatter plot with color-coding\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=reduced_embeddings[:, 0],\n",
        "    y=reduced_embeddings[:, 1],\n",
        "    mode='markers+text',\n",
        "    text=all_labels,\n",
        "    textposition='top center',\n",
        "    marker=dict(size=10, color=colors, showscale=False),\n",
        "    hoverinfo='text'\n",
        "))\n",
        "\n",
        "# Set plot title and axis labels\n",
        "fig.update_layout(\n",
        "    title=\"t-SNE Visualization of Family and Capital Words\",\n",
        "    xaxis=dict(title='t-SNE Dimension 1'),\n",
        "    yaxis=dict(title='t-SNE Dimension 2'),\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "S3RtFFhp3K2i",
        "outputId": "2782d5f8-33b4-4db9-d023-8d65790779e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unmatched family words: []\n",
            "Unmatched capital words: []\n",
            "Running t-SNE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"bf4ec9f1-a306-4018-82be-794745fa0144\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf4ec9f1-a306-4018-82be-794745fa0144\")) {                    Plotly.newPlot(                        \"bf4ec9f1-a306-4018-82be-794745fa0144\",                        [{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"showscale\":false,\"size\":10},\"mode\":\"markers+text\",\"text\":[\"granddaughter\",\"niece\",\"girl\",\"stepdaughter\",\"daughter\",\"stepfather\",\"uncle\",\"boy\",\"grandmother\",\"man\",\"mother\",\"mom\",\"stepmother\",\"grandson\",\"wife\",\"sister\",\"grandfather\",\"queen\",\"policeman\",\"stepson\",\"son\",\"groom\",\"daughters\",\"father\",\"dad\",\"grandma\",\"brother\",\"king\",\"stepbrother\",\"she\",\"prince\",\"her\",\"princess\",\"woman\",\"stepsister\",\"aunt\",\"grandpa\",\"his\",\"policewoman\",\"bride\",\"sisters\",\"sons\",\"brothers\",\"husband\",\"nephew\",\"he\",\"spain\",\"athens\",\"hanoi\",\"islamabad\",\"bern\",\"canberra\",\"canada\",\"iraq\",\"cuba\",\"switzerland\",\"helsinki\",\"tehran\",\"bangkok\",\"france\",\"moscow\",\"finland\",\"norway\",\"iran\",\"paris\",\"england\",\"china\",\"ottawa\",\"oslo\",\"madrid\",\"london\",\"italy\",\"tokyo\",\"kabul\",\"afghanistan\",\"sweden\",\"berlin\",\"thailand\",\"germany\",\"greece\",\"baghdad\",\"egypt\",\"russia\",\"stockholm\",\"havana\",\"cairo\",\"vietnam\",\"rome\",\"pakistan\",\"australia\",\"beijing\",\"japan\"],\"textposition\":\"top center\",\"x\":[-2.6919212341308594,-2.8823130130767822,-2.631176233291626,-1.4779407978057861,-2.0631303787231445,-0.9239190220832825,-3.5264155864715576,-2.6676385402679443,-4.131072044372559,-2.136171340942383,-2.377253293991089,-4.7268805503845215,-0.6246022582054138,-2.9256672859191895,-1.5595120191574097,-3.349881887435913,-3.6313037872314453,0.7223312854766846,-2.8558032512664795,-1.5236821174621582,-2.142101287841797,-4.263514041900635,-2.6251728534698486,-2.4549410343170166,-4.578139781951904,-5.2688164710998535,-3.299919366836548,0.6251332759857178,-0.4892195761203766,-0.8086543083190918,0.38319140672683716,-0.9762747883796692,0.3515610098838806,-2.1883649826049805,-0.07060375064611435,-3.9618654251098633,-5.336475372314453,-0.9616527557373047,-2.903315544128418,-4.144293308258057,-4.545849323272705,-2.6796505451202393,-4.531562805175781,-1.5121124982833862,-3.060246229171753,-0.797083854675293,5.548666000366211,3.642636775970459,2.1718661785125732,1.6433342695236206,2.5133328437805176,2.057394504547119,5.396042346954346,1.844403624534607,3.951960325241089,4.242621421813965,2.970149517059326,2.1520466804504395,1.0382188558578491,5.28129243850708,2.730865955352783,3.9601407051086426,4.28412389755249,2.1920509338378906,3.897204875946045,5.032954216003418,6.864070415496826,2.624366044998169,3.04899525642395,6.44345235824585,4.340407371520996,5.337287425994873,6.928164005279541,1.5433675050735474,1.5979384183883667,4.352566719055176,5.347326755523682,0.7620746493339539,5.519291400909424,4.676379680633545,1.7674423456192017,3.7846860885620117,5.722477912902832,2.8971056938171387,2.062227487564087,3.039095401763916,2.0316731929779053,5.180290699005127,1.186579704284668,5.512894630432129,0.7294161319732666,6.568545341491699],\"y\":[-5.891636371612549,-5.260158061981201,-2.4625933170318604,-6.317110061645508,-5.133479118347168,-5.365518093109131,-4.830349445343018,-2.5878286361694336,-5.213285446166992,-1.8655036687850952,-4.216548919677734,-6.3905744552612305,-5.541527271270752,-5.874752998352051,-4.201897621154785,-3.9706714153289795,-5.506871700286865,-2.7362148761749268,-0.6170107126235962,-5.945700168609619,-5.1256632804870605,-1.8617525100708008,-6.997218608856201,-4.468553066253662,-6.255159378051758,-5.546818256378174,-4.173157215118408,-2.8359363079071045,-6.38677978515625,-1.519910216331482,-3.452441453933716,-2.217888116836548,-3.503586769104004,-1.885237216949463,-6.2858099937438965,-4.841081142425537,-5.5669636726379395,-2.2659335136413574,-0.451336145401001,-1.929469108581543,-3.603452682495117,-6.9901909828186035,-3.6200835704803467,-4.0335235595703125,-5.045401573181152,-1.4602105617523193,5.0346856117248535,5.151346683502197,3.486886739730835,4.829592704772949,3.0172975063323975,2.3647043704986572,2.817631483078003,7.013803482055664,7.543819427490234,2.55869722366333,3.560215950012207,5.13465690612793,3.373716115951538,4.335792541503906,4.567317962646484,3.372457504272461,3.216144323348999,6.393935680389404,1.3649189472198486,4.568663597106934,3.1501424312591553,1.9590826034545898,3.5362117290496826,5.953700065612793,4.5518341064453125,5.363080978393555,4.0853071212768555,5.063019752502441,6.877052307128906,3.4106736183166504,1.5841035842895508,3.242357015609741,4.111966609954834,5.730861186981201,5.393907070159912,6.193482398986816,3.9088547229766846,3.1328508853912354,3.6894824504852295,5.854981899261475,7.759705066680908,6.216334819793701,6.3466877937316895,3.0757408142089844,4.273473262786865,3.8259198665618896],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"t-SNE Visualization of Family and Capital Words\"},\"xaxis\":{\"title\":{\"text\":\"t-SNE Dimension 1\"}},\"yaxis\":{\"title\":{\"text\":\"t-SNE Dimension 2\"}},\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bf4ec9f1-a306-4018-82be-794745fa0144');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the vocabulary size\n",
        "vocab_size = len(model.index_to_key)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmC0Xwdc5AHf",
        "outputId": "72b7420a-7601-43fe-8dd6-e5b2d21d4928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load the word embeddings (make sure the model is already loaded)\n",
        "word_to_index = {word: idx for idx, word in enumerate(model.index_to_key)}\n",
        "\n",
        "# Step 2: Load the analogy dataset\n",
        "analogy_df = pd.read_csv('TestSet_sample.csv')\n",
        "\n",
        "# Step 3: Extract words by category\n",
        "def extract_words_by_category(df, category):\n",
        "    words = set(df[df['category'] == category][['word_one', 'word_two', 'word_three', 'word_four']].values.flatten())\n",
        "    words = [word.lower() for word in words if word.lower() in word_to_index]\n",
        "    return words\n",
        "\n",
        "family_words = extract_words_by_category(analogy_df, 'family')\n",
        "capital_words = extract_words_by_category(analogy_df, 'capital-common-countries')\n",
        "\n",
        "# Debugging: Print unmatched words\n",
        "unmatched_family = [word for word in family_words if word not in word_to_index]\n",
        "unmatched_capital = [word for word in capital_words if word not in word_to_index]\n",
        "print(f\"Unmatched family words: {unmatched_family}\")\n",
        "print(f\"Unmatched capital words: {unmatched_capital}\")\n",
        "\n",
        "# Ensure categories are not empty\n",
        "if not family_words or not capital_words:\n",
        "    raise ValueError(\"One of the categories has no valid words in the vocabulary.\")\n",
        "\n",
        "# Step 4: Extract embeddings for each category\n",
        "def get_embeddings_for_words(words):\n",
        "    return np.array([model[word] for word in words])\n",
        "\n",
        "family_embeddings = get_embeddings_for_words(family_words)\n",
        "capital_embeddings = get_embeddings_for_words(capital_words)\n",
        "\n",
        "# Combine all embeddings and labels\n",
        "all_embeddings = np.vstack([family_embeddings, capital_embeddings])\n",
        "all_labels = family_words + capital_words\n",
        "\n",
        "# Step 5: Apply t-SNE on the combined embeddings (3D version)\n",
        "print(\"Running 3D t-SNE...\")\n",
        "tsne = TSNE(n_components=3, random_state=0, perplexity=30)\n",
        "reduced_embeddings = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Step 6: Create a 3D scatter plot using Plotly with color-coding by category\n",
        "colors = ['blue'] * len(family_words) + ['green'] * len(capital_words)  # Assign colors based on category\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add 3D scatter plot with color-coding\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=reduced_embeddings[:, 0],\n",
        "    y=reduced_embeddings[:, 1],\n",
        "    z=reduced_embeddings[:, 2],\n",
        "    mode='markers+text',\n",
        "    text=all_labels,\n",
        "    textposition='top center',\n",
        "    marker=dict(size=8, color=colors, opacity=0.8),\n",
        "    hoverinfo='text'\n",
        "))\n",
        "\n",
        "# Set plot title and axis labels\n",
        "fig.update_layout(\n",
        "    title=\"3D t-SNE Visualization of Family and Capital Words\",\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='t-SNE Dimension 1'),\n",
        "        yaxis=dict(title='t-SNE Dimension 2'),\n",
        "        zaxis=dict(title='t-SNE Dimension 3')\n",
        "    ),\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "eTidau75HT82",
        "outputId": "20faed26-9ea6-4d56-fbe3-4e5710884655"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unmatched family words: []\n",
            "Unmatched capital words: []\n",
            "Running 3D t-SNE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"32d199fa-ae2a-43a9-8512-d8599556465c\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"32d199fa-ae2a-43a9-8512-d8599556465c\")) {                    Plotly.newPlot(                        \"32d199fa-ae2a-43a9-8512-d8599556465c\",                        [{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"opacity\":0.8,\"size\":8},\"mode\":\"markers+text\",\"text\":[\"grandma\",\"man\",\"brother\",\"groom\",\"sister\",\"aunt\",\"grandfather\",\"father\",\"dad\",\"stepdaughter\",\"boy\",\"policewoman\",\"husband\",\"prince\",\"granddaughter\",\"mom\",\"mother\",\"uncle\",\"sisters\",\"brothers\",\"girl\",\"queen\",\"grandson\",\"daughters\",\"stepbrother\",\"stepfather\",\"stepson\",\"niece\",\"nephew\",\"his\",\"daughter\",\"grandpa\",\"king\",\"princess\",\"stepsister\",\"son\",\"wife\",\"policeman\",\"her\",\"stepmother\",\"sons\",\"woman\",\"bride\",\"she\",\"grandmother\",\"he\",\"iran\",\"sweden\",\"cairo\",\"canberra\",\"havana\",\"moscow\",\"tokyo\",\"germany\",\"ottawa\",\"tehran\",\"hanoi\",\"bern\",\"baghdad\",\"stockholm\",\"beijing\",\"france\",\"china\",\"kabul\",\"oslo\",\"egypt\",\"bangkok\",\"norway\",\"madrid\",\"paris\",\"australia\",\"helsinki\",\"athens\",\"pakistan\",\"england\",\"switzerland\",\"spain\",\"london\",\"islamabad\",\"iraq\",\"cuba\",\"thailand\",\"berlin\",\"russia\",\"canada\",\"afghanistan\",\"rome\",\"italy\",\"greece\",\"japan\",\"finland\",\"vietnam\"],\"textposition\":\"top center\",\"x\":[-0.9564404,6.6664696,-57.110584,-36.337997,-61.30802,10.007491,-88.96832,-29.534405,32.891674,-90.29467,-16.583838,-47.72223,111.476036,-16.396622,-59.449272,9.227673,42.239693,-62.9639,-75.73394,-78.16361,-14.163837,42.123093,-87.6488,-68.90698,-109.34433,-86.695496,-98.46833,-70.32495,-50.985836,-35.321396,-65.80932,-12.865873,10.6443405,-31.59311,-123.27473,-19.619223,-40.78571,-42.91452,-52.479717,121.89544,-85.26915,20.265463,-36.197605,-32.730545,35.185223,-3.0660272,80.231865,-9.740404,18.063353,65.31521,16.226103,55.284435,17.255827,88.50478,74.7463,60.294403,-113.95354,0.41637412,46.162918,-4.4571457,94.45131,116.47035,-38.172966,-86.58684,30.922506,23.356155,39.413437,56.789936,69.04573,4.21152,8.218814,29.77997,-13.133334,105.203995,86.9559,87.55886,39.926437,104.63041,58.25139,58.03854,50.15098,48.497307,-9.779493,37.020683,99.6949,1.6558417,52.679947,13.896786,26.366104,-119.40906,21.12605,100.48299],\"y\":[96.95619,74.1302,-51.12159,-11.686329,-15.518614,46.827797,57.281807,-28.130613,106.356285,17.40987,69.710625,119.262405,36.59176,57.471073,-66.75622,125.317116,-30.882568,33.677628,-0.27994007,33.970848,42.776676,92.16873,-45.253098,69.86216,26.494144,5.7166753,-39.92471,-11.255403,18.01523,30.71153,-40.461964,-9.878255,101.37982,39.625927,-2.5061324,-66.197945,-36.281033,97.496414,47.982353,-18.07462,80.70525,94.95038,2.0074503,67.05712,113.43164,56.983772,-78.430214,-11.222016,5.967055,45.003784,16.668924,-46.171875,-24.514174,31.489985,3.6981144,-14.417757,-32.8307,18.924221,19.409992,-14.378608,-37.764004,35.311287,-94.789764,-93.024895,-1.1317774,-30.642874,43.63359,-52.171482,-48.3032,-126.64424,-64.50848,-17.431303,-58.58635,-15.364006,34.800236,-35.043877,29.53757,7.31179,4.94363,1.6146404,-97.83912,57.975407,-56.205856,-71.97635,66.13153,-82.73146,-103.79909,-107.31557,-48.745567,19.518406,-42.020657,-71.71034],\"z\":[51.740173,-24.866125,81.31684,-43.532257,83.90257,-92.65154,-13.633165,56.26202,-50.977768,72.119576,-54.300842,-2.1447818,74.450005,71.98312,34.508205,-34.54537,98.12479,12.150923,-75.58439,-81.431595,-26.601072,5.45708,20.004654,59.269787,23.125662,-8.71961,63.057766,36.69393,44.248272,-61.438023,-18.646648,108.477684,8.703691,93.65392,44.944225,69.57193,10.711686,-25.150007,-36.320625,56.36798,31.043694,90.71943,-14.95224,16.671532,46.80087,12.489609,-25.88433,-90.58684,-50.974567,56.382042,5.2940016,0.1437977,-14.715402,-48.529156,52.056732,-23.035585,-20.010372,44.768646,-24.302818,22.022066,-4.196892,-26.533043,-24.13972,-5.5008106,57.431004,-62.69898,24.61967,48.559586,-57.612732,-30.846342,17.347557,27.192326,-106.08387,-49.28682,-4.1890817,-98.70725,94.58359,9.805287,11.881059,-76.45055,-59.724106,-44.57943,-28.0002,-21.91803,20.56424,-63.951572,23.920183,14.669826,-94.95449,-48.125492,54.967907,30.64858],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"3D t-SNE Visualization of Family and Capital Words\"},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"t-SNE Dimension 1\"}},\"yaxis\":{\"title\":{\"text\":\"t-SNE Dimension 2\"}},\"zaxis\":{\"title\":{\"text\":\"t-SNE Dimension 3\"}}},\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('32d199fa-ae2a-43a9-8512-d8599556465c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}